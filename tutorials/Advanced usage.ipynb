{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Spanner Workbench Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you will learn some advanced features of spanner workbench:\n",
    "* [rgxlog with native python](#native_python)\n",
    "* [changing the default magic_session](#changing_session)\n",
    "* [dymamic rules and queries](#dynmaic_calls)\n",
    "* [processing query result with python](#query_result_processing)\n",
    "* [importing relations from dataframes](#import_from_df)\n",
    "* [creating and adding optimization passes](#optimization_passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using native Python<a class=\"anchor\" id=\"native_python\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When rgxlog is loaded, a default session (`rgxlog.magic_session`) is created behind the scenes. This is the session that %%rgxlog uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a session manually enables one to dynamically generate queries, facts, and rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rgxlog\n",
    "session = rgxlog.magic_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.run_commands('''\n",
    "    new uncle(str, str)\n",
    "    uncle(\"benjen\", \"jon\")''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'uncle(\"ned\", Y)':\n",
      "[]\n",
      "\n",
      "printing results for query 'uncle(\"robb\", Y)':\n",
      "[]\n",
      "\n",
      "printing results for query 'uncle(\"benjen\", Y)':\n",
      "  Y\n",
      "-----\n",
      " jon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for maybe_uncle in ['ned', 'robb', 'benjen']:\n",
    "    result = session.run_commands(f'?uncle(\"{maybe_uncle}\",Y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the session of the magic cells<a class=\"anchor\" id=\"changing_session\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where you want to work with a custom session, but still make use of the magic system, you can overide the session used by the magic system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rgxlog  # default session starts here\n",
    "from rgxlog import Session\n",
    "\n",
    "another_session=Session()\n",
    "old_magic_session = rgxlog.magic_session\n",
    "rgxlog.magic_session = another_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'uncle(X, Y)':\n",
      "  X  |  Y\n",
      "-----+------\n",
      " bob | greg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "# we're now using the new session\n",
    "new uncle(str, str)\n",
    "uncle(\"bob\", \"greg\")\n",
    "?uncle(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to the old session\n",
    "rgxlog.magic_session = old_magic_session\n",
    "%rgxlog uncle(\"jim\", \"dwight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: uncle(str, str)\n",
      "    (1) (computed) add_fact: uncle(\"benjen\", \"jon\")\n",
      "    (2) (computed) query: uncle(\"ned\", Y)\n",
      "    (3) (computed) query: uncle(\"robb\", Y)\n",
      "    (4) (computed) query: uncle(\"benjen\", Y)\n",
      "    (5) (computed) add_fact: uncle(\"jim\", \"dwight\")\n",
      "\n",
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: uncle(str, str)\n",
      "    (1) (computed) add_fact: uncle(\"bob\", \"greg\")\n",
      "    (2) (computed) query: uncle(X, Y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rgxlog.magic_session._parse_graph)\n",
    "print(another_session._parse_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing magics with dynamic session calls<a class=\"anchor\" id=\"dynmaic_calls\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the GPA example from the introductory tutorial.\n",
    "What if we want to have multiple rules each looking for GPAs of students in different classes.\n",
    "We wouldnt want to manually write a rule for every single subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python-rgxlog interface functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can either write our data manually, or import it from a csv/dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%rgxlog\n",
    "new lecturer(str, str)\n",
    "lecturer(\"rick\", \"physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "lecturer_df = DataFrame(([[\"walter\",\"chemistry\"], [\"linus\", \"operating_systems\"]]))\n",
    "session.import_relation_from_df(lecturer_df, relation_name=\"lecturer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abigail,operating_systems\r\n",
      "jordan,chemistry\r\n",
      "gale,operating_systems\r\n",
      "howard,chemistry\r\n",
      "howard,physics\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat enrolled.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.import_relation_from_csv(\"enrolled.csv\", relation_name=\"enrolled\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa(X, Y)':\n",
      "    X    |   Y\n",
      "---------+-----\n",
      " abigail | 100\n",
      " jordan  |  80\n",
      "  gale   |  79\n",
      " howard  |  60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "enrolled(\"abigail\", \"chemistry\")\n",
    "gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\"\n",
    "\n",
    "gpa(Student,Grade) <- py_rgx_string(gpa_str, \"(\\w+).*?(\\d+)\")->(Student, Grade),enrolled(Student,X)\n",
    "\n",
    "?gpa(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using rgxlog in python loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the rules using a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    gpa_of_chemistry_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"chemistry\")\n",
      "    \n",
      "\n",
      "    gpa_of_physics_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"physics\")\n",
      "    \n",
      "\n",
      "    gpa_of_operation_systems_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"operation_systems\")\n",
      "    \n",
      "\n",
      "    gpa_of_magic_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"magic\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "subjects = [\n",
    "    \"chemistry\",\n",
    "    \"physics\",\n",
    "    \"operation_systems\",\n",
    "    \"magic\",\n",
    "]\n",
    "\n",
    "for subject in subjects:\n",
    "    rule = f\"\"\"\n",
    "    gpa_of_{subject}_students(Student, Grade) <- gpa(Student, Grade), enrolled(Student, \"{subject}\")\n",
    "    \"\"\"\n",
    "    session.run_commands(rule)\n",
    "    print(rule)  # we print the rule here to show you what strings are sent to the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we can use the dynamically defined rules in a magic cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa_of_operation_systems_students(X, Y)':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%rgxlog\n",
    "?gpa_of_operation_systems_students(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also query dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'gpa_of_chemistry_students(Student, Grade)':\n",
      "  Student  |   Grade\n",
      "-----------+---------\n",
      "  abigail  |     100\n",
      "  jordan   |      80\n",
      "  howard   |      60\n",
      "\n",
      "printing results for query 'gpa_of_physics_students(Student, Grade)':\n",
      "  Student  |   Grade\n",
      "-----------+---------\n",
      "  howard   |      60\n",
      "\n",
      "printing results for query 'gpa_of_operation_systems_students(Student, Grade)':\n",
      "[]\n",
      "\n",
      "printing results for query 'gpa_of_magic_students(Student, Grade)':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjects = [\n",
    "    \"chemistry\",\n",
    "    \"physics\",\n",
    "    \"operation_systems\",\n",
    "    \"magic\",\n",
    "]\n",
    "\n",
    "for subject in subjects:\n",
    "    query = f\"\"\"\n",
    "    ?gpa_of_{subject}_students(Student, Grade)\n",
    "    \"\"\"\n",
    "    session.run_commands(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating rules Dynamically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here's a more complicated example where we create rgxlog code dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: uncle_aunt(A,Z) <- sibling(A,B), parent(B,Z)\n",
      "printing results for query 'uncle_aunt(X, Y)':\n",
      "  X  |   Y\n",
      "-----+--------\n",
      " dio | george\n",
      "\n",
      "running: grandparent(A,Z) <- parent(A,B), parent(B,Z)\n",
      "printing results for query 'grandparent(X, Y)':\n",
      "    X     |   Y\n",
      "----------+--------\n",
      " jonathan | joseph\n",
      "  george  |  holy\n",
      "  joseph  | jotaro\n",
      "\n",
      "running: great_aunt_uncle(A,Z) <- sibling(A,B), parent(B,C), parent(C,Z)\n",
      "printing results for query 'great_aunt_uncle(X, Y)':\n",
      "  X  |   Y\n",
      "-----+--------\n",
      " dio | joseph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rgxlog import magic_session\n",
    "\n",
    "%rgxlog new sibling(str, str)\n",
    "%rgxlog new parent(str, str)\n",
    "%rgxlog parent(\"jonathan\", \"george\")\n",
    "%rgxlog parent(\"george\", \"joseph\")\n",
    "%rgxlog parent(\"joseph\", \"holy\")\n",
    "%rgxlog parent(\"holy\", \"jotaro\")\n",
    "%rgxlog sibling(\"dio\", \"jonathan\")\n",
    "\n",
    "a = [\"parent\", \"uncle_aunt\", \"grandparent\", \"sibling\"]\n",
    "d = {\"uncle_aunt\": [\"sibling\", \"parent\"], \"grandparent\": [\"parent\", \"parent\"], \"great_aunt_uncle\": [\"sibling\", \"parent\", \"parent\"]}\n",
    "\n",
    "for key, steps in d.items():\n",
    "    # add the start of the rule\n",
    "    result = key + \"(A,Z) <- \"\n",
    "    for num, step in enumerate(steps):\n",
    "        # for every step in the list, add the condition: step(letter, next letter).\n",
    "        #  the first letter is always `A`, and the last is always `Z`\n",
    "        curr_letter = chr(num + ord(\"A\"))\n",
    "        result += step + \"(\" + curr_letter + \",\"\n",
    "        if (num == len(steps) - 1):\n",
    "            result += \"Z)\"\n",
    "        else:\n",
    "            result += chr(1 + ord(curr_letter)) + \"), \"\n",
    "    print(\"running:\", result)\n",
    "    magic_session.run_commands(result)\n",
    "    magic_session.run_commands(f\"?{key}(X,Y)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the result of a query in python and using the result in a new query<a class=\"anchor\" id=\"query_result_processing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can add `format_results=True` to `run_statements` to get the output as one of the following:\n",
    "1. `[]`, if the result is false,\n",
    "2. `[tuple()]`, if the result if true (the tuple is empty), or\n",
    "3. `pandas.DataFrame`, otherwise-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'buddies(First, Second)':\n",
      "  First  |  Second\n",
      "---------+----------\n",
      "   bob   |   greg\n",
      "  lenny  |  homer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = session.run_commands(f'''\n",
    "    new friends(str, str, str)\n",
    "    friends(\"bob\", \"greg\", \"clyde\")\n",
    "    friends(\"steven\", \"benny\", \"horace\")\n",
    "    friends(\"lenny\", \"homer\", \"toby\")\n",
    "    ?friends(X,Y,Z)''', print_results=False, format_results=True)\n",
    "\n",
    "# now we'll showcase processing the result with native python...\n",
    "# lets filter our tuples with some predicate:\n",
    "res = results[0].values.tolist()\n",
    "filtered = tuple(filter(lambda friends: 'bob' in friends or 'lenny' in friends, res))\n",
    "\n",
    "# and feed the matching tuples into a new query:\n",
    "session.run_commands('new buddies(str, str)')\n",
    "\n",
    "for first, second, _ in filtered:\n",
    "    session.run_commands(f'buddies(\"{first}\", \"{second}\")')\n",
    "\n",
    "result = session.run_commands(\"?buddies(First, Second)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a relation from a `DataFrame`<a class=\"anchor\" id=\"import_from_df\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, non-boolean query results are saved as a `DataFrame`.\n",
    "A relation can also be imported from a `DataFrame`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'ogres(X, Y)':\n",
      "   X   |    Y\n",
      "-------+------\n",
      " Shrek |   42\n",
      " Fiona | 1337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame([[\"Shrek\",42], [\"Fiona\", 1337]], columns=[\"name\", \"number\"])\n",
    "session.import_relation_from_df(df, relation_name=\"ogres\")\n",
    "%rgxlog ?ogres(X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Optimization Passes to the Pass Stack<a class=\"anchor\" id=\"optimization_passes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading this section, we will briefly explain how passes work.\n",
    "There are five kinds of passes:\n",
    "1. **AST transformation passes** - These passes convert the input program into AST.\n",
    "2. **semantic checks passes** - These passes check the corectness of the program (i.e. one of the passes asserts that all the relations used in the program were registerred before).\n",
    "3. **AST execution passes** - These passes traverse the AST and covert it to a `parse graph`. In addition they register new relations and handle variables assingments.\n",
    "4. **term graph passes** - These passes adds rules into the `term graph`.\n",
    "5. **execution pass** - This pass traverses the `parse graph` and finds queries. Then it computes them using the `term graph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of optimization passes:\n",
    "1. The first one, manipulates rules before they are added to the `term graph`.\n",
    "2. The second one, manipulates the structure of the `term graph`.\n",
    "\n",
    "note: It's also possible to optimize the execution function/pass (but we won't discuss it in this tutorial). \n",
    "    \n",
    "In this section, we will implement two simple optimization passes, one of each kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Manipulation Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations of  this kind traverse the `parse_graph` and find rules that weren't added to the `term graph`.\n",
    "Then, they update each rule - by modifying its body relations list.\n",
    "\n",
    "Here are some examples of possible optimization passes of this kind:\n",
    "1. An optimization that removes duplicated relations from a rule.\n",
    "   i.e., the rule `A(X) <- B(X), C(X), B(X)` contains the relation `B(X)` twice.\n",
    "   The optimization will transform the rule into `A(X) <- B(X), C(X)`.\n",
    "   \n",
    "2. An optimization that removes useless relations from a rule.\n",
    "   i.e. the rule `A(X) <- B(X), C(Y)` contains the useless relation `C(Y)`.\n",
    "   The optimization will transform the rule into `A(X) <- B(X)`.\n",
    "   \n",
    "Below is an implementation of the latter example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Example: Remove Useless Relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the actual implementation, we will implement it in psuedo code:\n",
    "```\n",
    "1. a. Add the free variables inside the rule head into a relevant_free_variables set.\n",
    "   b. Mark all relations as useless, except those with no free variables (they are always relevant).\n",
    "   \n",
    "2. Find all relations which contain at least one free variable inside the relevant_free_variables set.\n",
    "\n",
    "3. Unmark these relations (since they are relevant).\n",
    "\n",
    "4. Add all free variables of the unmarked relations into the relevant_free_variables set.\n",
    "\n",
    "5. Repeat steps 2, 3 and 4 until the set of the marked relations converge.\n",
    "```\n",
    "note that this is a fixed point algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Implementation of a generic fixed point algorithm - an algorithm that takes a step function and runs it until\n",
      "    some distance is zero or below a threshold.\n",
      "\n",
      "    @param start: a starting value.\n",
      "    @param step: a step function.\n",
      "    @param distance: a function that measures distance between the input and the output of the step function.\n",
      "    @param thresh: a distance threshold.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rgxlog.engine.utils.general_utils import fixed_point\n",
    "print(fixed_point.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    @param relation: a relation (either a normal relation or an ie relation).\n",
      "    @return: a set of the free variables used as output terms in the relation.\n",
      "            if the input is relation it returns it's free variables,\n",
      "            if the input is ie-relation it returns it's output free variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rgxlog.engine.utils.general_utils import get_output_free_var_names\n",
    "print(get_output_free_var_names.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    @param relation: a relation (either a normal relation or an ie relation).\n",
      "    @return: a set of the free variables used as input terms in the relation.\n",
      "             if the input is relation it returns it's free variables,\n",
      "             if the input is ie-relation it returns it's input free variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from rgxlog.engine.utils.general_utils import get_input_free_var_names\n",
    "print(get_input_free_var_names.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, lets implement the logic that removes useless relations from a rule\n",
    "def remove_useless_relations(rule):\n",
    "        \"\"\"\n",
    "        Finds redundant relations and removes them from the rule.\n",
    "        \n",
    "        @param rule: a rule.\n",
    "        \"\"\"\n",
    "        # step 1.a. Add the free variables inside the rule head into a relevant_free_variables set.\n",
    "        relevant_free_vars = set(rule.head_relation.get_term_list())  \n",
    "\n",
    "        # step 1.b. Mark all relations as useless, except those with no free variables (they are always relevant).\n",
    "        initial_useless_relations_and_types = [(rel, rel_type) for rel, rel_type in zip(rule.body_relation_list, rule.body_relation_type_list)\n",
    "                                               if len(get_output_free_var_names(rel)) != 0]\n",
    "        # implement steps 2, 3 and 4\n",
    "        def step_function(current_useless_relations_and_types):\n",
    "            \"\"\"\n",
    "            Used by fixed pont algorithm.\n",
    "\n",
    "            @param current_useless_relations_and_types: current useless relations and their types\n",
    "            @return: useless relations after considering the new relevant free vars.\n",
    "            \"\"\"\n",
    "\n",
    "            next_useless_relations_and_types = []\n",
    "            \n",
    "            # step 2 - Find all relations that has at least on free variable inside the relevant_free_variables set.\n",
    "            for relation, rel_type in current_useless_relations_and_types:\n",
    "                term_list = get_output_free_var_names(relation)\n",
    "                if len(relevant_free_vars.intersection(term_list)) == 0:\n",
    "                    next_useless_relations_and_types.append((relation, rel_type))\n",
    "                else:\n",
    "                    # step 3 - Unmark relation. The relations isn't added to the useless list, and thus it's unmarked.\n",
    "                    # step 4 - Add all the free variables of the unmarked relation into the relevant_free_variables set.\n",
    "                    relevant_free_vars.update(term_list)\n",
    "                    relevant_free_vars.update(get_input_free_var_names(relation))\n",
    "\n",
    "            return next_useless_relations_and_types\n",
    "\n",
    "        # step 5 - fixed ponint. note that the distance function returns zero if and only if len(x) equals len(y).\n",
    "        useless_relations_and_types = fixed_point(start=initial_useless_relations_and_types, step=step_function, distance=lambda x, y: int(len(x) != len(y)))\n",
    "        \n",
    "        # this part filters the useless relation from the rule\n",
    "        relevant_relations_and_types = set(zip(rule.body_relation_list, rule.body_relation_type_list)).difference(useless_relations_and_types)\n",
    "        new_body_relation_list, new_body_relation_type_list = zip(*relevant_relations_and_types)\n",
    "        rule.body_relation_list = list(new_body_relation_list)\n",
    "        rule.body_relation_type_list = list(new_body_relation_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgxlog.engine.state.graphs import GraphBase, EvalState, STATE, TYPE, VALUE\n",
    "from rgxlog.engine.utils.passes_utils import ParseNodeType\n",
    "from rgxlog.engine.passes.lark_passes import GenericPass  # base class of all the passes\n",
    "    \n",
    "\n",
    "# finally, the implementation of the optimization pass\n",
    "class RemoveUselessRelationsFromRule(GenericPass):\n",
    "    \"\"\"\n",
    "    This pass removes duplicated relations from a rule.\n",
    "    For example, the rule A(X) <- B(X), C(Y) contains a redundant relation (C(Y)).\n",
    "    After this pass the rule will be A(X) <- B(X).\n",
    "\n",
    "    @note: in the rule A(X) <- B(X, Y), C(Y); C(Y) is not redundant!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, parse_graph: GraphBase, **kwargs):\n",
    "        self.parse_graph = parse_graph\n",
    "            \n",
    "    def run_pass(self, **kwargs):\n",
    "        # get the new rules in the parse graph\n",
    "        rules = self.parse_graph.get_all_nodes_with_attributes(type=ParseNodeType.RULE, state=EvalState.NOT_COMPUTED)\n",
    "        for rule_node_id in rules:\n",
    "            rule_node = self.parse_graph[rule_node_id]\n",
    "            rule = rule_node[VALUE]\n",
    "            remove_useless_relations(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the pass stack looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass stack before:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tAddRulesToComputationTermGraph\n",
      "\n",
      "Pass stack after:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tRemoveUselessRelationsFromRule\n",
      "\tAddRulesToComputationTermGraph\n"
     ]
    }
   ],
   "source": [
    "def print_pass_stack(pass_stack):\n",
    "    \"\"\"prints pass stack in a nice format\"\"\"\n",
    "    \n",
    "    for pass_ in pass_stack:\n",
    "        print(\"\\t\" + pass_.__name__)\n",
    "        \n",
    "magic_session = Session()  # reset the magic session\n",
    "\n",
    "original_pass_stack = magic_session.get_pass_stack()  # save the original pass stack\n",
    "\n",
    "new_pass_stack = original_pass_stack.copy()\n",
    "term_graph_pass = new_pass_stack.pop()  # remove last pass (this pass adds rules to term graph)\n",
    "new_pass_stack.extend([RemoveUselessRelationsFromRule, term_graph_pass])\n",
    "\n",
    "magic_session.set_pass_stack(new_pass_stack)\n",
    "\n",
    "print(f\"Pass stack before:\")\n",
    "print_pass_stack(original_pass_stack)\n",
    "\n",
    "print(\"\\nPass stack after:\")\n",
    "print_pass_stack(magic_session.get_pass_stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the effect of this pass on the parse graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse graph of unmodified pass stack:\n",
      "\n",
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Good(int)\n",
      "    (1) (computed) relation_declaration: Bad(int)\n",
      "    (2) (computed) rule: Example(X) <- Good(X), Bad(Y)\n",
      "\n",
      "\n",
      "Parse graph after adding optimization pass:\n",
      "\n",
      "(__rgxlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Good(int)\n",
      "    (1) (computed) relation_declaration: Bad(int)\n",
      "    (2) (computed) rule: Example(X) <- Good(X)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "new Good(int)\n",
    "new Bad(int)\n",
    "\n",
    "Example(X) <- Good(X), Bad(Y)\n",
    "\"\"\"\n",
    "\n",
    "def run_commands_and_print_parse_graph(session):\n",
    "    session.run_commands(commands)\n",
    "    print(session._parse_graph)\n",
    "    \n",
    "\n",
    "print(\"Parse graph of unmodified pass stack:\\n\")\n",
    "run_commands_and_print_parse_graph(Session()) \n",
    "\n",
    "print(\"\\nParse graph after adding optimization pass:\\n\")\n",
    "run_commands_and_print_parse_graph(magic_session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in the rule node!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Graph Structure Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations of this kind traverse the `term_graph` and modify its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Graph Structure\n",
    "Before reading on, it is important to understand how the `term_graph` looks like in order to understand the terminology used - there is detailed documentation inside the class docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       This class transforms each rule node into an execution graph and adds it to the term graph.\n",
      "\n",
      "       The purpose of the term graph is to store relationships about the following entities:\n",
      "           1. The rule head.\n",
      "           2. The body rule relations.\n",
      "           3. The body base relations and ie relations.\n",
      "           4. All the computation paths of the rule head.\n",
      "\n",
      "       Lets look on the following RGXLog program:\n",
      "           new A(int, int)\n",
      "           new B(int, int)\n",
      "           C(X, Y) <- A(X, Y)\n",
      "           D(X, Y) <- C(X, Y)\n",
      "           D(X, Y) <- A(X, 1), B(X, Y), ID(X) -> (Y)  # ID is some ie function\n",
      "\n",
      "       We will explain the meaning of the 4 entities w.r.t the rules of D:\n",
      "           1. The rule head is: D(X, Y)\n",
      "           2. The body relations are: C(X, Y) in the first rule (there are None in the second rule).\n",
      "           3. The base relations are: A(X, 1) and B(X, Y) in the second rule (there are None in the first rule).\n",
      "           4. The computation paths of the rule are the paths of first rule and second rule.\n",
      "\n",
      "       The structure of the term graph:\n",
      "\n",
      "           * Each rule relation has a node in the term graph, we call this node 'rule_rel node'.\n",
      "             Every rule_rel node is connected to a global root.\n",
      "\n",
      "           * The rule_rel node is connected to a node we call 'union_node'.\n",
      "\n",
      "           * The union_node is connected to all the relation's computation paths.\n",
      "\n",
      "           * Each computation path starts with a node we call 'project_node' that projects the columns of the relation it\n",
      "             gets (the project_node is connected to the union_node).\n",
      "\n",
      "           * Under the project_node, there is a node we call 'join_node' that joins all the body relations of the rule.\n",
      "             There are specials cases when this node isn't used:\n",
      "               - there is only one relation in the rule's body.\n",
      "               - all the body relation don't have free variables.\n",
      "\n",
      "           * Each ie relation in the body of the rule is connected to the join node by a node we call 'calc_node'.\n",
      "             This node is connected to another join node that connects all the ie relation's bounding relations.\n",
      "\n",
      "           * Each rule relation in the body relation is connected to the join node by a node we call 'get_rel node'.\n",
      "             The get_rel node is connected to the corresponding rule root.\n",
      "\n",
      "           * Each base relation is connected to the join node.\n",
      "\n",
      "           * In case the is relation with same free var (e.g. A(X, X)) or relation with some constant value (e.g. A(1, x))\n",
      "             we use a node we call 'select_node' that deals with filtering tuples form the relation. The select node is\n",
      "             connected to the join node and the get_rel node is connected to the select node.\n",
      "\n",
      "       For the RGXLog program above, the term graph will be:\n",
      "           global root\n",
      "\n",
      "               rule_rel node (of C)\n",
      "                   union node\n",
      "                       project node\n",
      "                           get_rel node (get A)  @note: there isn't join node since there is only one body relation.\n",
      "\n",
      "               rule_rel node (of D)\n",
      "                   union node\n",
      "                       project node\n",
      "                           get_rel node (get C)  @note: there isn't join node since there is only one body relation.\n",
      "                               rule_rel node (of C)\n",
      "\n",
      "                       project node\n",
      "                           join node (join A, B and ID)\n",
      "                               get_rel node (get B)\n",
      "                               select_node (select from A)\n",
      "                                   get_rel node (get A)\n",
      "                               calc node (of ID)\n",
      "                                   join node (join A and B)\n",
      "                                       get_rel node (get B)         @note: this get_rel node is the same one from above.\n",
      "                                       select_node (select from A)  @note: this select node is the same one from above.\n",
      "                                           get_rel node (get A)\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "from rgxlog.engine.state.graphs import TermGraphBase, TermGraph, TermNodeType\n",
    "print(TermGraph.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Optimization\n",
    "Here are some examples of possible optimization passes of this kind:\n",
    "1. An optimization that removes join nodes which have only one child relation.\n",
    "   Note: this optimization already exists so there is no need to implement it.\n",
    "   \n",
    "2. An optimization that removes project nodes whose input is a single-column relation.\n",
    "   \n",
    "Here's the implementation of the second example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Example: Remove Redundant Project Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following optimization will traverse the term graph and find all project nodes that has input relation with arity of one.<br>\n",
    "In this case, the project node is redundant and therefore, we remove it from the term graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the actual implementation, we will implement it in a psuedo code:\n",
    "```\n",
    "1. Find all project nodes and their union nodes parents (inside the term graph).\n",
    "\n",
    "2. For each project node\n",
    "\n",
    "    2.1. Check if the arity of the project node's input relation is one, using the following steps:\n",
    "        a. get project's node child - we will denote it as child_node.\n",
    "        b. if type of child_node is GET_REL or RULE_REL or CALC node child, return true if arity of the relation stored in child_node is one.\n",
    "        c. if type of child_node is SELECT, return true if there is only one free variable in the relation stored in the child of the child_node. \n",
    "        d. if type of child_node is project:\n",
    "              (i). get input relaations from all of it's children nodes\n",
    "              (ii). return true if the arity of the join of all the input relations is one.\n",
    "              \n",
    "    2.2 if has arity of one, remove the node from the graph by connecting it's child to it's parent.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def is_relation_has_one_free_var(relation) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether relation is only one free variable.\n",
    "\n",
    "    @param relation_: a relation or an ie_relation.\n",
    "    \"\"\"\n",
    "\n",
    "    return len(relation.get_term_list()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function implements step 2 in the pseudo code\n",
    "def is_input_relation_of_node_has_arity_of_one(term_graph: TermGraphBase, node_id) -> bool:\n",
    "    \"\"\"\n",
    "    @param node_id: id of the node.\n",
    "    @note: we expect id of project/join node.\n",
    "    @return: the arity of the relation that the node gets during the execution.\n",
    "    \"\"\"\n",
    "\n",
    "    # staep 2.1.a: note that this methods suppose to work for both project nodes and join nodes.\n",
    "    # project nodes always have one child while join nodes always have more than one child.\n",
    "    # for that reason, we traverse all the children of the node.\n",
    "    node_ids = term_graph.get_children(node_id)\n",
    "    \n",
    "    # used to compute arity of final relation\n",
    "    free_vars: Set[str] = set()\n",
    "\n",
    "    for node_id in node_ids:\n",
    "        node_attrs = term_graph[node_id]\n",
    "        node_type = node_attrs[TYPE]\n",
    "        \n",
    "        # step 2.1.b\n",
    "        if node_type in (TermNodeType.GET_REL, TermNodeType.RULE_REL, TermNodeType.CALC):\n",
    "            relation = node_attrs[VALUE]\n",
    "            # if relation has more than one free var we can't prune the project\n",
    "            if not is_relation_has_one_free_var(relation):\n",
    "                return False\n",
    "\n",
    "            free_vars |= set(relation.get_term_list())\n",
    "            \n",
    "        # step 2.1.c\n",
    "        elif node_type is TermNodeType.SELECT:\n",
    "            relation_child_id = next(iter(term_graph.get_children(node_id)))\n",
    "            relation = term_graph[relation_child_id][VALUE]\n",
    "            if not is_relation_has_one_free_var(relation):\n",
    "                return False\n",
    "\n",
    "            relation_free_vars = [var for var, var_type in zip(relation.get_term_list(), relation.get_type_list()) if var_type is DataTypes.free_var_name]\n",
    "            free_vars |= set(relation_free_vars)\n",
    "        \n",
    "        # step 2.1.d\n",
    "        elif node_type is TermNodeType.JOIN:\n",
    "            # the input of project node is the same as the input of the join node\n",
    "            return is_input_relation_of_node_has_arity_of_one(term_graph, node_id)\n",
    "\n",
    "    return len(free_vars) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, lets implement the optimization pass class\n",
    "class PruneUnnecessaryProjectNodes(GenericPass):\n",
    "    \"\"\"\n",
    "    This class prunes project nodes that gets a relation with one column (therefore, the project is redundant).\n",
    "\n",
    "    For example, the rule A(X) <- B(X) will yield the following term graph:\n",
    "\n",
    "        rule_rel node (of A)\n",
    "            union node\n",
    "                project node (on X)\n",
    "                   get_rel node (get B)\n",
    "\n",
    "        since we project a relation with one column, after this pass the term graph will be:\n",
    "\n",
    "        rule_rel node (of A)\n",
    "            union node\n",
    "                get_rel node (get B)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, term_graph: TermGraphBase, **kwargs):\n",
    "        self.term_graph = term_graph\n",
    "\n",
    "    def run_pass(self, **kwargs):\n",
    "        self.prune_project_nodes()\n",
    "        \n",
    "    def prune_project_nodes(self) -> None:\n",
    "        \"\"\"\n",
    "        Prunes the redundant project nodes.\n",
    "        \"\"\"\n",
    "\n",
    "        project_nodes = self.term_graph.get_all_nodes_with_attributes(type=TermNodeType.PROJECT)\n",
    "        for project_id in project_nodes:\n",
    "            if is_input_relation_of_node_has_arity_of_one(self.term_graph, project_id):\n",
    "                # step 2.2\n",
    "                self.term_graph.add_edge(self.term_graph.get_parent(project_id), self.term_graph.get_child(project_id))\n",
    "                self.term_graph.remove_node(project_id)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is adding this pass to the pass stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pass stack:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tAddRulesToComputationTermGraph\n",
      "\tPruneUnnecessaryProjectNodes\n"
     ]
    }
   ],
   "source": [
    "magic_session = Session()  # reset the magic_session\n",
    "\n",
    "new_pass_stack = magic_session.get_pass_stack()\n",
    "new_pass_stack.append(PruneUnnecessaryProjectNodes)\n",
    "magic_session.set_pass_stack(new_pass_stack)\n",
    "\n",
    "print(\"New pass stack:\")\n",
    "print_pass_stack(magic_session.get_pass_stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets see how this pass modifies the term graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term graph of unmodified pass stack:\n",
      "\n",
      "(__rgxlog_root) (not_computed) root\n",
      "    (A) (not_computed) rule_rel: A(X)\n",
      "        (0) (not_computed) union\n",
      "            (1) (not_computed) project: ['X']\n",
      "                (2) (not_computed) get_rel: B(X)\n",
      "\n",
      "DependencyGraph is:\n",
      "__rgxlog_root\n",
      "    A\n",
      "\n",
      "\n",
      "Term graph after adding optimization pass:\n",
      "\n",
      "(__rgxlog_root) (not_computed) root\n",
      "    (A) (not_computed) rule_rel: A(X)\n",
      "        (0) (not_computed) union\n",
      "            (2) (not_computed) get_rel: B(X)\n",
      "\n",
      "DependencyGraph is:\n",
      "__rgxlog_root\n",
      "    A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "new B(int)\n",
    "A(X) <- B(X)\n",
    "\"\"\"\n",
    "\n",
    "def run_commands_and_print_term_graph(session):\n",
    "    session.run_commands(commands)\n",
    "    print(session._term_graph)\n",
    "    \n",
    "\n",
    "print(\"Term graph of unmodified pass stack:\\n\")\n",
    "run_commands_and_print_term_graph(Session()) \n",
    "\n",
    "print(\"\\nTerm graph after adding optimization pass:\\n\")\n",
    "run_commands_and_print_term_graph(magic_session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the changes in the term_graph's structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Example: Overlapping Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another optimization example, this time without an implementation.\n",
    "It does the following:\n",
    "1. Finds overlapping structure of rules.\n",
    "2. Merges the overlapping structure and adds it to the term graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Example Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the following example:\n",
    "```\n",
    ">>> D(X,Y) <- A(X),B(Y),C(X,Y,Z)\n",
    ">>> E(X,Y) <- A(X),C(X,Y,Z), F(Z)\n",
    ">>> x(X,Y) <- E(X,Y)\n",
    ">>> x(X,Y) <- D(X,Y)\n",
    "```\n",
    "Without merging terms with overlapping structures,\n",
    "this would naively generate something that abstractly looks like this:\n",
    "<!--\n",
    " digraph G {\n",
    "   D_and [label=\"and\"]\n",
    "   E_and [label=\"and\"]\n",
    "   x->OR [style=dotted]\n",
    "   E->E_and [style=dotted]\n",
    "   D->D_and [style=dotted]\n",
    "   OR -> {D_and,E_and}\n",
    "   D_and ->{A,B,C}\n",
    "   E_and -> {A,C,F} \n",
    " }\n",
    "-->\n",
    "<img src=\"naive_term_graph.svg\">\n",
    "\n",
    "The weakness with this approach is that `A AND C` is computed twice.\n",
    "\n",
    "A version of the term graph that takes care to merge terms with overlapping structures would look more like this:\n",
    "<!--\n",
    " digraph G {\n",
    "   D_and [label=\"and\"]\n",
    "   E_and [label=\"and\"]\n",
    "   x->OR [style=dotted]\n",
    "   E->E_and [style=dotted]\n",
    "   D->D_and [style=dotted]\n",
    "   OR -> {D_and,E_and}\n",
    "   D_and ->{and,B}\n",
    "   E_and -> {and,F} \n",
    "   and -> {A,C}\n",
    " }\n",
    " -->\n",
    "<img src=\"shared_term_graph.svg\">\n",
    "\n",
    "Here, we realized that A,C is a joint component and that we need only compute it once.\n",
    "This would be the automatic equivalent of a smart programmer, refactoring the query above to look like\n",
    "\n",
    "```\n",
    ">>> TEMP(X,Y,Z) <- A(X), C(X,Y,Z)\n",
    ">>> D(X,Y) <- B(Y),TEMP(X,Y,Z)\n",
    ">>> E(X,Y) <- TEMP(X,Y,Z), F(Z)\n",
    ">>> x(X,Y) <- E(X,Y)\n",
    ">>> x(X,Y) <- D(X,Y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a pseudo implementation of this pass: \n",
    "```\n",
    "1. get all the registered rules by using term_graph.get_all_rules).\n",
    "\n",
    "2. find overlapping structure between rules (this step can be implemented in many different ways).\n",
    "\n",
    "3. create new rule that consists of the overlapping structure.\n",
    "\n",
    "4. add this new rule to the term graph by using term_graph.add_rule_to_term_graph.\n",
    "\n",
    "5. updated the previous rule to use the newly created rule.\n",
    "\n",
    "6. added the rules to the term graph.\n",
    "\n",
    "7. delete the previous versions of the rule from the term graph by using term_graph.remove_rule.\n",
    "```\n",
    "\n",
    "For example, \n",
    "if the following rules were registered:\n",
    "1. ```D(X,Y) <- A(X),B(Y),C(X,Y,Z)```\n",
    "2. ```E(X,Y) <- A(X),C(X,Y,Z), F(Z)```\n",
    "\n",
    "In the second step of the algorithm, we will find that both rules share the structure ```A(X),C(X,Y,Z)```.<br>\n",
    "In the third step we will create a new relation ```TEMP(X,Y,Z) <- A(X), C(X,Y,Z)```, and add it to the term graph.<br>\n",
    "In the fifth step we will modify to original rules in the following way:\n",
    "1. ```D(X,Y) <- B(Y),TEMP(X,Y,Z)```\n",
    "2. ```E(X,Y) <- TEMP(X,Y,Z), F(Z)```\n",
    "\n",
    "And then we will add them to the term graph.<br>\n",
    "The last step will delete the old rules from the term graph."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
